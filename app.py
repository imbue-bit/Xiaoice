import streamlit as st
from video_processor import VideoProcessor
from PIL import Image
import base64
from io import BytesIO

st.set_page_config(page_title="Xiaoice | è§†é¢‘å¯¹è¯", layout="wide", page_icon="ğŸ¬")

st.title("ğŸ¬ Xiaoice Video LLM: ä¸ä½ çš„è§†é¢‘å¯¹è¯")
st.markdown("""
æ¬¢è¿ä½¿ç”¨ Xiaoiceï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºè®ºæ–‡ã€Šé€šè¿‡è‡ªç›‘ç£æ—¶ç©ºè¯­ä¹‰ç‰¹å¾èšç±»å®ç°å…è®­ç»ƒçš„è§†é¢‘ç†è§£ã€‹çš„äº¤äº’å¼åº”ç”¨ã€‚

**å·¥ä½œæµç¨‹:**
1.  **ä¸Šä¼ è§†é¢‘**: åœ¨å·¦ä¾§ä¸Šä¼ ä¸€ä¸ªè§†é¢‘æ–‡ä»¶ (å»ºè®®ä½¿ç”¨1-3åˆ†é’Ÿçš„ .mp4 æ–‡ä»¶ä»¥è·å¾—æœ€ä½³ä½“éªŒ)ã€‚
2.  **è‡ªåŠ¨åˆ†æ**: AIå°†è‡ªåŠ¨å¤„ç†è§†é¢‘ï¼Œæå–ç‰¹å¾ï¼Œåˆ†å‰²äº‹ä»¶ï¼Œå‘ç°åœºæ™¯ï¼Œå¹¶ç”Ÿæˆæ‘˜è¦ã€‚
3.  **å¼€å§‹å¯¹è¯**: åˆ†æå®Œæˆåï¼Œæ‚¨å¯ä»¥åœ¨ä¸‹æ–¹çš„å¯¹è¯æ¡†ä¸­å°±è§†é¢‘å†…å®¹å‘AIæé—®ã€‚
""")

if 'processor' not in st.session_state:
    st.session_state.processor = VideoProcessor()
if 'video_summary' not in st.session_state:
    st.session_state.video_summary = None
if 'messages' not in st.session_state:
    st.session_state.messages = []

processor = st.session_state.processor

with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®")
    uploaded_file = st.file_uploader("ä¸Šä¼ ä½ çš„è§†é¢‘æ–‡ä»¶", type=["mp4", "mov", "avi"])
    
    st.subheader("åˆ†æå‚æ•°")
    sampling_rate = st.slider("é‡‡æ ·ç‡ (å¸§/ç§’)", 1, 5, 2, help="ä»è§†é¢‘ä¸­æ¯ç§’æå–å¤šå°‘å¸§è¿›è¡Œåˆ†æã€‚æ›´é«˜çš„å€¼ä¼šæ›´ç²¾ç¡®ä½†æ›´æ…¢ã€‚")
    num_segments_kts = st.slider("KTSæœŸæœ›ç‰‡æ®µæ•°", 5, 50, 15, help="æœŸæœ›å°†è§†é¢‘åˆ†å‰²æˆå¤šå°‘ä¸ªåŸºæœ¬äº‹ä»¶ç‰‡æ®µã€‚è¿™ä¼šå½±å“åœºæ™¯å‘ç°çš„ç²’åº¦ã€‚")

    if st.button("ğŸš€ å¼€å§‹åˆ†æè§†é¢‘", use_container_width=True, disabled=not uploaded_file):
        st.session_state.video_summary = None
        st.session_state.messages = []
        
        video_bytes = uploaded_file.getvalue()
        with st.status("æ­£åœ¨å¤„ç†è§†é¢‘ï¼Œè¯·ç¨å€™...", expanded=True) as status:
            st.session_state.video_summary = processor.process_video(video_bytes, sampling_rate, num_segments_kts)
            status.update(label="è§†é¢‘å¤„ç†å®Œæˆï¼", state="complete", expanded=False)

st.header("ğŸ“Š è§†é¢‘æ‘˜è¦")

if st.session_state.video_summary:
    for scene_name, scene_data in st.session_state.video_summary.items():
        with st.expander(f"**{scene_name}**: {scene_data['description']}", expanded=True):
            col1, col2 = st.columns([1, 2])
            with col1:
                img_data = base64.b64decode(scene_data['keyframe_base64'])
                img = Image.open(BytesIO(img_data))
                st.image(img, caption=f"{scene_name} çš„ä»£è¡¨æ€§å…³é”®å¸§", use_column_width=True)
            with col2:
                st.write(f"**AI ç”Ÿæˆçš„ Overview:**")
                st.info(scene_data['description'])
                st.write(f"**æ„æˆ:** æ­¤åœºæ™¯ç”± **{scene_data['segment_count']}** ä¸ªç›¸ä¼¼çš„äº‹ä»¶ç‰‡æ®µç»„æˆã€‚")
else:
    st.info("è¯·åœ¨å·¦ä¾§ä¸Šä¼ è§†é¢‘å¹¶ç‚¹å‡»â€œå¼€å§‹åˆ†æè§†é¢‘â€ä»¥æŸ¥çœ‹ç»“æœã€‚")

st.divider()

st.header("ğŸ’¬ ä¸è§†é¢‘å¯¹è¯")

if st.session_state.video_summary:
    # æ˜¾ç¤ºå†å²å¯¹è¯æ¶ˆæ¯
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # æ¥æ”¶ç”¨æˆ·è¾“å…¥
    if prompt := st.chat_input("è¯·å°±è§†é¢‘å†…å®¹å‘æˆ‘æé—®..."):
        # å°†ç”¨æˆ·æ¶ˆæ¯æ·»åŠ åˆ°å†å²è®°å½•å¹¶æ˜¾ç¤º
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # ç”Ÿæˆå¹¶æ˜¾ç¤ºAIçš„å›ç­”
        with st.chat_message("assistant"):
            with st.spinner("æ€è€ƒä¸­..."):
                response = processor.answer_question(prompt, st.session_state.video_summary)
                st.markdown(response)
        
        # å°†AIçš„å›ç­”æ·»åŠ åˆ°å†å²è®°å½•
        st.session_state.messages.append({"role": "assistant", "content": response})
else:
    st.info("å®Œæˆè§†é¢‘åˆ†æåï¼Œæ‚¨å¯ä»¥åœ¨è¿™é‡Œå¼€å§‹å¯¹è¯ã€‚")
